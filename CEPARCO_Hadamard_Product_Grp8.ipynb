{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hadamard Product\n"
      ],
      "metadata": {
        "id": "RHSitXcNGdrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C Implementation"
      ],
      "metadata": {
        "id": "G8QdrL1hGmVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hadamard_c.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "void dumpArr(size_t row, size_t col, float arr[row][col])\n",
        "{\n",
        "  printf(\"Array output: \\n\");\n",
        "  for (size_t i = 0; i < row; ++i) {\n",
        "    for (size_t j = 0; j < col; ++j) {\n",
        "      printf(\"%.2f \", arr[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "void C_hadamard(size_t ARR_SIZE, float z[ARR_SIZE][ARR_SIZE], float x[ARR_SIZE][ARR_SIZE], float y[ARR_SIZE][ARR_SIZE])\n",
        "{\n",
        "  for (size_t i = 0; i < ARR_SIZE; ++i) {\n",
        "    for (size_t j = 0; j < ARR_SIZE; ++j) {\n",
        "      z[i][j] = x[i][j] * y[i][j];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARR_SIZE = 4096;\n",
        "  size_t NUM_EXEC = 10;\n",
        "\n",
        "  // https://stackoverflow.com/questions/3911400/how-to-pass-2d-array-matrix-in-a-function-in-c\n",
        "  // int (*array)[cols] = malloc(rows * cols * sizeof(array[0][0]));\n",
        "  float (*x)[ARR_SIZE] = malloc(ARR_SIZE * ARR_SIZE * sizeof(x[0][0]));\n",
        "  float (*y)[ARR_SIZE] = malloc(ARR_SIZE * ARR_SIZE * sizeof(y[0][0]));\n",
        "  float (*z)[ARR_SIZE] = malloc(ARR_SIZE * ARR_SIZE * sizeof(z[0][0]));\n",
        "\n",
        "  for (size_t i = 0; i < ARR_SIZE; ++i) {\n",
        "    for (size_t j = 0; j < ARR_SIZE; ++j) {\n",
        "      x[i][j] = 1.0f;\n",
        "      y[i][j] = 2.0f;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  clock_t start, end;\n",
        "  double elapse, time_taken;\n",
        "  elapse = 0.0f;\n",
        "  // fill in cache\n",
        "  C_hadamard(ARR_SIZE, z, x, y);\n",
        "\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "      start = clock();\n",
        "      C_hadamard(ARR_SIZE, z, x, y);\n",
        "      end = clock();\n",
        "      time_taken = (end-start)*1E6/CLOCKS_PER_SEC;\n",
        "      elapse +=  time_taken;\n",
        "  }\n",
        "\n",
        "\n",
        "  size_t err_count = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARR_SIZE; ++i) {\n",
        "    for (size_t j = 0; j < ARR_SIZE; ++j) {\n",
        "      if( (x[i][j] * y[i][j]) != z[i][j] ) {\n",
        "        err_count++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  free(x);\n",
        "  free(y);\n",
        "  free(z);\n",
        "  // dumpArr(ARR_SIZE, ARR_SIZE, z);\n",
        "  printf(\"Function in C took an average time of %lf in microseconds\\n\", elapse/NUM_EXEC);\n",
        "  printf(\"Total error count: %lu\", err_count);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8h8Du6hGlTh",
        "outputId": "787e363f-e0b4-46f7-cc78-9e4489efd398"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hadamard_c.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "gcc -Wall -Wextra -pedantic -o hadamard_c hadamard_c.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOOtNqO2G0GL",
        "outputId": "2bb8ddf7-faeb-40b5-ef77-2a6be7e0ce74"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "chmod +X ./hadamard_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY5DWgV8i_lN",
        "outputId": "393a4dfe-6f76-4635-f180-ce70c7fbafb8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./hadamard_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVYofQrbjH4J",
        "outputId": "032fb75b-5073-4a02-c5f0-c083aa220b40"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function in C took an average time of 49203.200000 in microseconds\n",
            "Total error count: 0"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6PLW8KuGVJQ",
        "outputId": "53c1b67c-5579-48be-fa06-91c94009963a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hadamard_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile hadamard_cuda.cu\n",
        "#include <cstddef>\n",
        "#include <cstdio>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "void dump_arr(size_t numCol, size_t numRow, float* Arr)\n",
        "{\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      for (size_t i = 0; i < numRow; ++i) {\n",
        "      printf(\"%.2f \", Arr[i * numCol + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "void C_Hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  for (size_t i = 0; i < numRow; ++i) {\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      Z[i * numCol + j] = X[i * numCol + j] * Y[i * numCol + j];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  size_t threadRowID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t threadColId = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  // Z[threadColId * numCol + threadRowID] = X[threadColId * numCol + threadRowID] * Y[threadColId * numCol + threadRowID];\n",
        "  // if (threadRowID < numRow && threadColId < numCol) {\n",
        "  Z[threadRowID * numCol + threadColId] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "  // }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARRAY_DIM = 1024; // 4096;\n",
        "  const size_t ARRAY_BYTES = ARRAY_DIM * ARRAY_DIM * sizeof(float);\n",
        "  size_t NUM_EXEC = 30;\n",
        "\n",
        "  // Array Initialization\n",
        "  float* X;\n",
        "  float* Y;\n",
        "  float* Z;\n",
        "\n",
        "  // Initialize C implementation of Hadamard Product, reference for error checking\n",
        "  float* C;\n",
        "  C = (float*)malloc(ARRAY_DIM * ARRAY_DIM * sizeof(float));\n",
        "\n",
        "  // Array Malloc\n",
        "  cudaMallocManaged(&X, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Z, ARRAY_BYTES);\n",
        "\n",
        "  // get gpu ID\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  // Mem advise\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create GPU page memory\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // initialize array contents\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j < ARRAY_DIM; ++j) {\n",
        "      X[ARRAY_DIM * i + j] = 1;\n",
        "      Y[ARRAY_DIM * i + j] = 1;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // \"Prefetch data\" from CPU-GPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  C_Hadamard(ARRAY_DIM, ARRAY_DIM, C, X, Y);\n",
        "\n",
        "  // setup CUDA kernel\n",
        "  // https://www.cs.emory.edu/~cheung/Courses/355/Syllabus/94-CUDA/2D-grids.html\n",
        "  size_t threadDimBlockx = 8;\n",
        "  size_t threadDimBlocky = 8;\n",
        "\n",
        "  dim3 blockShape = dim3(threadDimBlockx, threadDimBlocky);\n",
        "  dim3 gridShape = dim3(ARRAY_DIM/threadDimBlockx, ARRAY_DIM/threadDimBlocky);\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "    cuda_hadamard <<< gridShape, blockShape >>> (ARRAY_DIM, ARRAY_DIM, Z, X, Y);\n",
        "  }\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // \"Prefetch data\" from GPU-CPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, X);\n",
        "  // printf(\"\\n\\n\");\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, Z);\n",
        "\n",
        "  // error checking\n",
        "  size_t errCount = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j <ARRAY_DIM; ++j ) {\n",
        "      if (C[i * ARRAY_DIM + j] != Z[i * ARRAY_DIM + j]) {\n",
        "        errCount++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"Total error count: %lu\", errCount);\n",
        "\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "  cudaFree(Z);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -o hadamard_cuda hadamard_cuda.cu -arch=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IvYTE5tHlHN",
        "outputId": "d2a10be8-6887-4391-f991-636434c48ee7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./hadamard_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqbB9dSwNIw1",
        "outputId": "9ccb6f2f-60a5-4618-e2e8-8a3b16b7c12d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==11450== NVPROF is profiling process 11450, command: ./hadamard_cuda\n",
            "Total error count: 0==11450== Profiling application: ./hadamard_cuda\n",
            "==11450== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  3.1060ms        30  103.53us  96.960us  104.90us  cuda_hadamard(unsigned long, unsigned long, float*, float*, float*)\n",
            "      API calls:   96.35%  208.91ms         3  69.637ms  37.393us  208.81ms  cudaMallocManaged\n",
            "                    1.74%  3.7723ms         8  471.54us  12.358us  1.2170ms  cudaMemPrefetchAsync\n",
            "                    1.36%  2.9569ms         1  2.9569ms  2.9569ms  2.9569ms  cudaDeviceSynchronize\n",
            "                    0.30%  641.26us         3  213.75us  171.17us  238.65us  cudaFree\n",
            "                    0.16%  344.48us        30  11.482us  3.8230us  169.19us  cudaLaunchKernel\n",
            "                    0.07%  149.81us       114  1.3140us     110ns  59.816us  cuDeviceGetAttribute\n",
            "                    0.01%  29.894us         4  7.4730us  2.0710us  22.175us  cudaMemAdvise\n",
            "                    0.01%  11.967us         1  11.967us  11.967us  11.967us  cuDeviceGetName\n",
            "                    0.00%  6.7300us         1  6.7300us  6.7300us  6.7300us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.3600us         1  2.3600us  2.3600us  2.3600us  cuModuleGetLoadingMode\n",
            "                    0.00%  1.9550us         1  1.9550us  1.9550us  1.9550us  cudaGetDevice\n",
            "                    0.00%  1.7380us         3     579ns     131ns  1.3440us  cuDeviceGetCount\n",
            "                    0.00%  1.0240us         2     512ns     172ns     852ns  cuDeviceGet\n",
            "                    0.00%     373ns         1     373ns     373ns     373ns  cuDeviceTotalMem\n",
            "                    0.00%     238ns         1     238ns     238ns     238ns  cuDeviceGetUuid\n",
            "\n",
            "==11450== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       4  2.0000MB  2.0000MB  2.0000MB  8.000000MB  698.7770us  Host To Device\n",
            "       2  2.0000MB  2.0000MB  2.0000MB  4.000000MB  321.5340us  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hadamard_cuda16x16.cu\n",
        "#include <cstddef>\n",
        "#include <cstdio>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "void dump_arr(size_t numCol, size_t numRow, float* Arr)\n",
        "{\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      for (size_t i = 0; i < numRow; ++i) {\n",
        "      printf(\"%.2f \", Arr[i * numCol + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "void C_Hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  for (size_t i = 0; i < numRow; ++i) {\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      Z[i * numCol + j] = X[i * numCol + j] * Y[i * numCol + j];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  size_t threadRowID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t threadColId = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  // Z[threadColId * numCol + threadRowID] = X[threadColId * numCol + threadRowID] * Y[threadColId * numCol + threadRowID];\n",
        "  // if (threadRowID < numRow && threadColId < numCol) {\n",
        "  Z[threadRowID * numCol + threadColId] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "  // }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARRAY_DIM = 2048; // 4096;\n",
        "  const size_t ARRAY_BYTES = ARRAY_DIM * ARRAY_DIM * sizeof(float);\n",
        "  size_t NUM_EXEC = 30;\n",
        "\n",
        "  // Array Initialization\n",
        "  float* X;\n",
        "  float* Y;\n",
        "  float* Z;\n",
        "\n",
        "  // Initialize C implementation of Hadamard Product, reference for error checking\n",
        "  float* C;\n",
        "  C = (float*)malloc(ARRAY_DIM * ARRAY_DIM * sizeof(float));\n",
        "\n",
        "  // Array Malloc\n",
        "  cudaMallocManaged(&X, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Z, ARRAY_BYTES);\n",
        "\n",
        "  // get gpu ID\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  // Mem advise\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create GPU page memory\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // initialize array contents\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j < ARRAY_DIM; ++j) {\n",
        "      X[ARRAY_DIM * i + j] = 1;\n",
        "      Y[ARRAY_DIM * i + j] = 1;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // \"Prefetch data\" from CPU-GPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  C_Hadamard(ARRAY_DIM, ARRAY_DIM, C, X, Y);\n",
        "\n",
        "  // setup CUDA kernel\n",
        "  // https://www.cs.emory.edu/~cheung/Courses/355/Syllabus/94-CUDA/2D-grids.html\n",
        "  size_t threadDimBlockx = 16;\n",
        "  size_t threadDimBlocky = 16;\n",
        "\n",
        "  dim3 blockShape = dim3(threadDimBlockx, threadDimBlocky);\n",
        "  // https://selkie.macalester.edu/csinparallel/modules/GPUProgramming/build/html/CUDA2D/CUDA2D.html\n",
        "  dim3 gridShape = dim3(ARRAY_DIM/threadDimBlockx, ARRAY_DIM/threadDimBlocky);\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "    cuda_hadamard <<< gridShape, blockShape >>> (ARRAY_DIM, ARRAY_DIM, Z, X, Y);\n",
        "  }\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // \"Prefetch data\" from GPU-CPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, X);\n",
        "  // printf(\"\\n\\n\");\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, Z);\n",
        "\n",
        "  // error checking\n",
        "  size_t errCount = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j <ARRAY_DIM; ++j ) {\n",
        "      if (C[i * ARRAY_DIM + j] != Z[i * ARRAY_DIM + j]) {\n",
        "        errCount++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"Total error count: %lu\", errCount);\n",
        "\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "  cudaFree(Z);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhmyyAcsPeZC",
        "outputId": "fb034215-948d-4355-c052-a3eaa41034e3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hadamard_cuda16x16.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -o hadamard_cuda16x16 hadamard_cuda16x16.cu -arch=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq2jFtTTPqzx",
        "outputId": "49f920f3-0113-4104-928a-90ff1820bf3e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./hadamard_cuda16x16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl8y8ZCgPoUr",
        "outputId": "157abf50-d209-4abf-d4ce-319dfc63fcc9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==11567== NVPROF is profiling process 11567, command: ./hadamard_cuda16x16\n",
            "Total error count: 0==11567== Profiling application: ./hadamard_cuda16x16\n",
            "==11567== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  17.801ms        30  593.36us  591.96us  594.65us  cuda_hadamard(unsigned long, unsigned long, float*, float*, float*)\n",
            "      API calls:   87.09%  223.39ms         3  74.464ms  44.159us  223.29ms  cudaMallocManaged\n",
            "                    6.91%  17.719ms         1  17.719ms  17.719ms  17.719ms  cudaDeviceSynchronize\n",
            "                    4.98%  12.774ms         8  1.5968ms  14.694us  3.9716ms  cudaMemPrefetchAsync\n",
            "                    0.82%  2.1044ms         3  701.46us  566.70us  827.91us  cudaFree\n",
            "                    0.12%  298.26us        30  9.9420us  3.7800us  174.56us  cudaLaunchKernel\n",
            "                    0.07%  187.79us       114  1.6470us     120ns  93.753us  cuDeviceGetAttribute\n",
            "                    0.01%  21.175us         4  5.2930us  1.3630us  15.722us  cudaMemAdvise\n",
            "                    0.00%  12.248us         1  12.248us  12.248us  12.248us  cuDeviceGetName\n",
            "                    0.00%  5.6740us         1  5.6740us  5.6740us  5.6740us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.4850us         3     828ns     153ns  2.1240us  cuDeviceGetCount\n",
            "                    0.00%  2.3670us         1  2.3670us  2.3670us  2.3670us  cudaGetDevice\n",
            "                    0.00%  1.0610us         2     530ns     225ns     836ns  cuDeviceGet\n",
            "                    0.00%     422ns         1     422ns     422ns     422ns  cuDeviceTotalMem\n",
            "                    0.00%     408ns         1     408ns     408ns     408ns  cuModuleGetLoadingMode\n",
            "                    0.00%     245ns         1     245ns     245ns     245ns  cuDeviceGetUuid\n",
            "\n",
            "==11567== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      16  2.0000MB  2.0000MB  2.0000MB  32.00000MB  2.776618ms  Host To Device\n",
            "       8  2.0000MB  2.0000MB  2.0000MB  16.00000MB  1.285844ms  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA with Shared Memory"
      ],
      "metadata": {
        "id": "v37VyGxhnuuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hadamard_cuda_shared16x16.cu\n",
        "#include <cstddef>\n",
        "#include <cstdio>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "void dump_arr(size_t numCol, size_t numRow, float* Arr)\n",
        "{\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      for (size_t i = 0; i < numRow; ++i) {\n",
        "      printf(\"%.2f \", Arr[i * numCol + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "\n",
        "  size_t threadRowID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t threadColId = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  __shared__ float shData[1];\n",
        "\n",
        "  shData[0] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  Z[threadRowID * numCol + threadColId] = shData[0]; // shared maemory\n",
        "\n",
        "  // Z[threadRowID * numCol + threadColId] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARRAY_DIM =   4096; //1024, 2048, 4096\n",
        "  const size_t ARRAY_BYTES = ARRAY_DIM * ARRAY_DIM * sizeof(float);\n",
        "  size_t NUM_EXEC = 30;\n",
        "\n",
        "  // Array Initialization\n",
        "  float* X;\n",
        "  float* Y;\n",
        "  float* Z;\n",
        "\n",
        "  // Initialize C implementation of Hadamard Product, reference for error checking\n",
        "  // float* C;\n",
        "  // C = (float*)malloc(ARRAY_DIM * ARRAY_DIM * sizeof(float));\n",
        "\n",
        "  // Array Malloc\n",
        "  cudaMallocManaged(&X, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Z, ARRAY_BYTES);\n",
        "\n",
        "  // get gpu ID\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  // Mem advise\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create GPU page memory\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // initialize array contents\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j < ARRAY_DIM; ++j) {\n",
        "      X[ARRAY_DIM * i + j] = 1;\n",
        "      Y[ARRAY_DIM * i + j] = 1;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // \"Prefetch data\" from CPU-GPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // setup CUDA kernel\n",
        "  // https://www.cs.emory.edu/~cheung/Courses/355/Syllabus/94-CUDA/2D-grids.html\n",
        "  size_t threadDimBlockx = 32; // 8, 16, 32\n",
        "  size_t threadDimBlocky = 32; // 8, 16, 32\n",
        "\n",
        "  dim3 blockShape = dim3(threadDimBlockx, threadDimBlocky);\n",
        "  // https://selkie.macalester.edu/csinparallel/modules/GPUProgramming/build/html/CUDA2D/CUDA2D.html\n",
        "  // https://medium.com/@harsh20111997/cuda-programming-2d-convolution-8476300f566e\n",
        "  dim3 gridShape = dim3( (ARRAY_DIM + threadDimBlockx - 1) / threadDimBlockx, (ARRAY_DIM + threadDimBlocky - 1)/threadDimBlocky );\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "    cuda_hadamard <<< gridShape, blockShape >>> (ARRAY_DIM, ARRAY_DIM, Z, X, Y);\n",
        "  }\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // \"Prefetch data\" from GPU-CPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "\n",
        "  // error checking\n",
        "  size_t errCount = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j <ARRAY_DIM; ++j ) {\n",
        "      if (X[i * ARRAY_DIM + j] * Y[i * ARRAY_DIM + j] != Z[i * ARRAY_DIM + j]) {\n",
        "        errCount++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"Total error count: %lu\", errCount);\n",
        "\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "  cudaFree(Z);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHYiwnponuU4",
        "outputId": "dd9904ad-a66b-4ade-b257-bf589a7bf2f7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hadamard_cuda_shared16x16.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -o hadamard_cuda_shared16x16 hadamard_cuda_shared16x16.cu -arch=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_8LPlWMn312",
        "outputId": "9c820aa3-5b02-47c0-d6df-aa2ca18170a3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./hadamard_cuda_shared16x16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5yu0MrvoIEQ",
        "outputId": "429b7d50-05f3-4e82-955a-c7226a34da5e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==18358== NVPROF is profiling process 18358, command: ./hadamard_cuda_shared16x16\n",
            "Total error count: 0==18358== Profiling application: ./hadamard_cuda_shared16x16\n",
            "==18358== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  133.26ms        30  4.4421ms  4.2487ms  4.5832ms  cuda_hadamard(unsigned long, unsigned long, float*, float*, float*)\n",
            "      API calls:   52.78%  213.56ms         3  71.187ms  27.666us  213.48ms  cudaMallocManaged\n",
            "                   32.92%  133.18ms         1  133.18ms  133.18ms  133.18ms  cudaDeviceSynchronize\n",
            "                   12.13%  49.059ms         8  6.1324ms  39.872us  15.974ms  cudaMemPrefetchAsync\n",
            "                    2.05%  8.2953ms         3  2.7651ms  2.3020ms  3.2580ms  cudaFree\n",
            "                    0.07%  296.74us        30  9.8910us  3.4590us  181.76us  cudaLaunchKernel\n",
            "                    0.04%  165.03us       114  1.4470us     113ns  63.037us  cuDeviceGetAttribute\n",
            "                    0.01%  21.497us         4  5.3740us  1.4250us  15.847us  cudaMemAdvise\n",
            "                    0.00%  13.398us         1  13.398us  13.398us  13.398us  cuDeviceGetName\n",
            "                    0.00%  7.9290us         1  7.9290us  7.9290us  7.9290us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8020us         3     600ns     213ns  1.3630us  cuDeviceGetCount\n",
            "                    0.00%  1.7060us         1  1.7060us  1.7060us  1.7060us  cudaGetDevice\n",
            "                    0.00%     958ns         2     479ns     171ns     787ns  cuDeviceGet\n",
            "                    0.00%     457ns         1     457ns     457ns     457ns  cuModuleGetLoadingMode\n",
            "                    0.00%     329ns         1     329ns     329ns     329ns  cuDeviceTotalMem\n",
            "                    0.00%     205ns         1     205ns     205ns     205ns  cuDeviceGetUuid\n",
            "\n",
            "==18358== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  11.10608ms  Host To Device\n",
            "      32  2.0000MB  2.0000MB  2.0000MB  64.00000MB  5.141878ms  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}