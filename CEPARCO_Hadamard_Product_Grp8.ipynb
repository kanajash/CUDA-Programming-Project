{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hadamard Product\n"
      ],
      "metadata": {
        "id": "RHSitXcNGdrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C Implementation"
      ],
      "metadata": {
        "id": "G8QdrL1hGmVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hadamard_c.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "void dumpArr(size_t row, size_t col, float arr[row][col])\n",
        "{\n",
        "  printf(\"Array output: \\n\");\n",
        "  for (size_t i = 0; i < row; ++i) {\n",
        "    for (size_t j = 0; j < col; ++j) {\n",
        "      printf(\"%.2f \", arr[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "void C_hadamard(size_t ARR_SIZE, float z[ARR_SIZE][ARR_SIZE], float x[ARR_SIZE][ARR_SIZE], float y[ARR_SIZE][ARR_SIZE])\n",
        "{\n",
        "  for (size_t i = 0; i < ARR_SIZE; ++i) {\n",
        "    for (size_t j = 0; j < ARR_SIZE; ++j) {\n",
        "      z[i][j] = x[i][j] * y[i][j];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARR_SIZE = 4096;\n",
        "  size_t NUM_EXEC = 10;\n",
        "\n",
        "  // https://stackoverflow.com/questions/3911400/how-to-pass-2d-array-matrix-in-a-function-in-c\n",
        "  // int (*array)[cols] = malloc(rows * cols * sizeof(array[0][0]));\n",
        "  float (*x)[ARR_SIZE] = malloc(ARR_SIZE * ARR_SIZE * sizeof(x[0][0]));\n",
        "  float (*y)[ARR_SIZE] = malloc(ARR_SIZE * ARR_SIZE * sizeof(y[0][0]));\n",
        "  float (*z)[ARR_SIZE] = malloc(ARR_SIZE * ARR_SIZE * sizeof(z[0][0]));\n",
        "\n",
        "  for (size_t i = 0; i < ARR_SIZE; ++i) {\n",
        "    for (size_t j = 0; j < ARR_SIZE; ++j) {\n",
        "      x[i][j] = 1.0f;\n",
        "      y[i][j] = 2.0f;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  clock_t start, end;\n",
        "  double elapse, time_taken;\n",
        "  elapse = 0.0f;\n",
        "  // fill in cache\n",
        "  C_hadamard(ARR_SIZE, z, x, y);\n",
        "\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "      start = clock();\n",
        "      C_hadamard(ARR_SIZE, z, x, y);\n",
        "      end = clock();\n",
        "      time_taken = (end-start)*1E6/CLOCKS_PER_SEC;\n",
        "      elapse +=  time_taken;\n",
        "  }\n",
        "\n",
        "\n",
        "  size_t err_count = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARR_SIZE; ++i) {\n",
        "    for (size_t j = 0; j < ARR_SIZE; ++j) {\n",
        "      if( (x[i][j] * y[i][j]) != z[i][j] ) {\n",
        "        err_count++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  free(x);\n",
        "  free(y);\n",
        "  free(z);\n",
        "  // dumpArr(ARR_SIZE, ARR_SIZE, z);\n",
        "  printf(\"Function in C took an average time of %lf in microseconds\\n\", elapse/NUM_EXEC);\n",
        "  printf(\"Total error count: %lu\", err_count);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8h8Du6hGlTh",
        "outputId": "475ced73-3dc2-4800-e5ea-a9f0b11eb3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hadamard_c.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "gcc -Wall -Wextra -pedantic -o hadamard_c hadamard_c.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOOtNqO2G0GL",
        "outputId": "0c9b1467-c86c-4d0c-edb0-5d4f3139cb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "chmod +X ./hadamard_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY5DWgV8i_lN",
        "outputId": "a1426308-8de3-43ce-82e1-8a48e60cb231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./hadamard_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVYofQrbjH4J",
        "outputId": "1333e873-b4ff-4fdb-9d46-f64373099e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function in C took an average time of 61122.800000 in microseconds\n",
            "Total error count: 0"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6PLW8KuGVJQ",
        "outputId": "f54fb874-23e3-4cff-dcb8-bc59ea71d18f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hadamard_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile hadamard_cuda.cu\n",
        "#include <cstddef>\n",
        "#include <cstdio>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "void dump_arr(size_t numCol, size_t numRow, float* Arr)\n",
        "{\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      for (size_t i = 0; i < numRow; ++i) {\n",
        "      printf(\"%.2f \", Arr[i * numCol + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "void C_Hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  for (size_t i = 0; i < numRow; ++i) {\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      Z[i * numCol + j] = X[i * numCol + j] * Y[i * numCol + j];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  size_t threadRowID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t threadColId = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  // Z[threadColId * numCol + threadRowID] = X[threadColId * numCol + threadRowID] * Y[threadColId * numCol + threadRowID];\n",
        "  // if (threadRowID < numRow && threadColId < numCol) {\n",
        "  Z[threadRowID * numCol + threadColId] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "  // }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARRAY_DIM = 4096;\n",
        "  const size_t ARRAY_BYTES = ARRAY_DIM * ARRAY_DIM * sizeof(float);\n",
        "  size_t NUM_EXEC = 30;\n",
        "\n",
        "  // Array Initialization\n",
        "  float* X;\n",
        "  float* Y;\n",
        "  float* Z;\n",
        "\n",
        "  // Initialize C implementation of Hadamard Product, reference for error checking\n",
        "  float* C;\n",
        "  C = (float*)malloc(ARRAY_DIM * ARRAY_DIM * sizeof(float));\n",
        "\n",
        "  // Array Malloc\n",
        "  cudaMallocManaged(&X, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Z, ARRAY_BYTES);\n",
        "\n",
        "  // get gpu ID\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  // Mem advise\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create GPU page memory\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // initialize array contents\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j < ARRAY_DIM; ++j) {\n",
        "      X[ARRAY_DIM * i + j] = 1;\n",
        "      Y[ARRAY_DIM * i + j] = 1;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // \"Prefetch data\" from CPU-GPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  C_Hadamard(ARRAY_DIM, ARRAY_DIM, C, X, Y);\n",
        "\n",
        "  // setup CUDA kernel\n",
        "  // https://www.cs.emory.edu/~cheung/Courses/355/Syllabus/94-CUDA/2D-grids.html\n",
        "  size_t threadDimBlockx = 8;\n",
        "  size_t threadDimBlocky = 8;\n",
        "\n",
        "  dim3 blockShape = dim3(threadDimBlockx, threadDimBlocky);\n",
        "  dim3 gridShape = dim3(ARRAY_DIM/threadDimBlockx, ARRAY_DIM/threadDimBlocky);\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "    cuda_hadamard <<< gridShape, blockShape >>> (ARRAY_DIM, ARRAY_DIM, Z, X, Y);\n",
        "  }\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // \"Prefetch data\" from GPU-CPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, X);\n",
        "  // printf(\"\\n\\n\");\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, Z);\n",
        "\n",
        "  // error checking\n",
        "  size_t errCount = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j <ARRAY_DIM; ++j ) {\n",
        "      if (C[i * ARRAY_DIM + j] != Z[i * ARRAY_DIM + j]) {\n",
        "        errCount++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"Total error count: %lu\", errCount);\n",
        "\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "  cudaFree(Z);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -o hadamard_cuda hadamard_cuda.cu -arch=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IvYTE5tHlHN",
        "outputId": "3a0664ea-c6c8-4223-c383-d3a3ba44d1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./hadamard_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqbB9dSwNIw1",
        "outputId": "69372182-e4a4-45c5-9bf3-1ebc65156a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==818== NVPROF is profiling process 818, command: ./hadamard_cuda\n",
            "==818== Profiling application: ./hadamard_cuda\n",
            "==818== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  66.104ms        30  2.2035ms  2.1959ms  2.2085ms  cuda_hadamard(unsigned long, unsigned long, float*, float*, float*)\n",
            "      API calls:   61.65%  239.87ms         3  79.956ms  32.372us  239.77ms  cudaMallocManaged\n",
            "                   17.67%  68.735ms         8  8.5919ms  64.788us  18.983ms  cudaMemPrefetchAsync\n",
            "                   16.95%  65.946ms         1  65.946ms  65.946ms  65.946ms  cudaDeviceSynchronize\n",
            "                    3.55%  13.819ms         3  4.6063ms  3.8403ms  5.5836ms  cudaFree\n",
            "                    0.11%  436.18us        30  14.539us  5.5870us  243.14us  cudaLaunchKernel\n",
            "                    0.05%  190.15us       114  1.6670us     200ns  75.262us  cuDeviceGetAttribute\n",
            "                    0.01%  32.732us         1  32.732us  32.732us  32.732us  cuDeviceGetName\n",
            "                    0.01%  26.857us         4  6.7140us  1.9560us  19.522us  cudaMemAdvise\n",
            "                    0.00%  7.4510us         1  7.4510us  7.4510us  7.4510us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1730us         1  2.1730us  2.1730us  2.1730us  cudaGetDevice\n",
            "                    0.00%  1.8960us         3     632ns     211ns  1.3820us  cuDeviceGetCount\n",
            "                    0.00%     919ns         2     459ns     200ns     719ns  cuDeviceGet\n",
            "                    0.00%     617ns         1     617ns     617ns     617ns  cuDeviceTotalMem\n",
            "                    0.00%     457ns         1     457ns     457ns     457ns  cuModuleGetLoadingMode\n",
            "                    0.00%     338ns         1     338ns     338ns     338ns  cuDeviceGetUuid\n",
            "\n",
            "==818== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  11.13607ms  Host To Device\n",
            "      32  2.0000MB  2.0000MB  2.0000MB  64.00000MB  5.141235ms  Device To Host\n",
            "Total error count: 0"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hadamard_cuda16x16.cu\n",
        "#include <cstddef>\n",
        "#include <cstdio>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "void dump_arr(size_t numCol, size_t numRow, float* Arr)\n",
        "{\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      for (size_t i = 0; i < numRow; ++i) {\n",
        "      printf(\"%.2f \", Arr[i * numCol + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "void C_Hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  for (size_t i = 0; i < numRow; ++i) {\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      Z[i * numCol + j] = X[i * numCol + j] * Y[i * numCol + j];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  size_t threadRowID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t threadColId = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  // Z[threadColId * numCol + threadRowID] = X[threadColId * numCol + threadRowID] * Y[threadColId * numCol + threadRowID];\n",
        "  // if (threadRowID < numRow && threadColId < numCol) {\n",
        "  Z[threadRowID * numCol + threadColId] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "  // }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARRAY_DIM = 4096;\n",
        "  const size_t ARRAY_BYTES = ARRAY_DIM * ARRAY_DIM * sizeof(float);\n",
        "  size_t NUM_EXEC = 30;\n",
        "\n",
        "  // Array Initialization\n",
        "  float* X;\n",
        "  float* Y;\n",
        "  float* Z;\n",
        "\n",
        "  // Initialize C implementation of Hadamard Product, reference for error checking\n",
        "  float* C;\n",
        "  C = (float*)malloc(ARRAY_DIM * ARRAY_DIM * sizeof(float));\n",
        "\n",
        "  // Array Malloc\n",
        "  cudaMallocManaged(&X, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Z, ARRAY_BYTES);\n",
        "\n",
        "  // get gpu ID\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  // Mem advise\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create GPU page memory\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // initialize array contents\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j < ARRAY_DIM; ++j) {\n",
        "      X[ARRAY_DIM * i + j] = 1;\n",
        "      Y[ARRAY_DIM * i + j] = 1;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // \"Prefetch data\" from CPU-GPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  C_Hadamard(ARRAY_DIM, ARRAY_DIM, C, X, Y);\n",
        "\n",
        "  // setup CUDA kernel\n",
        "  // https://www.cs.emory.edu/~cheung/Courses/355/Syllabus/94-CUDA/2D-grids.html\n",
        "  size_t threadDimBlockx = 16;\n",
        "  size_t threadDimBlocky = 16;\n",
        "\n",
        "  dim3 blockShape = dim3(threadDimBlockx, threadDimBlocky);\n",
        "  // https://selkie.macalester.edu/csinparallel/modules/GPUProgramming/build/html/CUDA2D/CUDA2D.html\n",
        "  dim3 gridShape = dim3(ARRAY_DIM/threadDimBlockx, ARRAY_DIM/threadDimBlocky);\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "    cuda_hadamard <<< gridShape, blockShape >>> (ARRAY_DIM, ARRAY_DIM, Z, X, Y);\n",
        "  }\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // \"Prefetch data\" from GPU-CPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, X);\n",
        "  // printf(\"\\n\\n\");\n",
        "  // dump_arr(ARRAY_DIM, ARRAY_DIM, Z);\n",
        "\n",
        "  // error checking\n",
        "  size_t errCount = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j <ARRAY_DIM; ++j ) {\n",
        "      if (C[i * ARRAY_DIM + j] != Z[i * ARRAY_DIM + j]) {\n",
        "        errCount++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"Total error count: %lu\", errCount);\n",
        "\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "  cudaFree(Z);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhmyyAcsPeZC",
        "outputId": "4d731711-19e5-4753-a5ed-4b90978cb0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hadamard_cuda16x16.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -o hadamard_cuda16x16 hadamard_cuda16x16.cu -arch=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq2jFtTTPqzx",
        "outputId": "c69121d5-9fa2-4d95-bb52-bd8c13e14111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./hadamard_cuda16x16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl8y8ZCgPoUr",
        "outputId": "bbd693d1-be40-41cf-93e4-ac43dd6424ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4109== NVPROF is profiling process 4109, command: ./hadamard_cuda16x16\n",
            "Total error count: 0==4109== Profiling application: ./hadamard_cuda16x16\n",
            "==4109== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  71.012ms        30  2.3671ms  2.3635ms  2.3706ms  cuda_hadamard(unsigned long, unsigned long, float*, float*, float*)\n",
            "      API calls:   47.71%  110.19ms         3  36.731ms  30.468us  110.05ms  cudaMallocManaged\n",
            "                   30.71%  70.933ms         1  70.933ms  70.933ms  70.933ms  cudaDeviceSynchronize\n",
            "                   17.73%  40.937ms         8  5.1171ms  42.417us  14.588ms  cudaMemPrefetchAsync\n",
            "                    3.61%  8.3321ms         3  2.7774ms  1.9757ms  3.3034ms  cudaFree\n",
            "                    0.16%  363.44us        30  12.114us  3.5660us  243.84us  cudaLaunchKernel\n",
            "                    0.06%  141.98us       114  1.2450us     107ns  58.433us  cuDeviceGetAttribute\n",
            "                    0.01%  22.066us         4  5.5160us  1.2140us  17.240us  cudaMemAdvise\n",
            "                    0.01%  11.806us         1  11.806us  11.806us  11.806us  cuDeviceGetName\n",
            "                    0.00%  5.1260us         1  5.1260us  5.1260us  5.1260us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1780us         1  2.1780us  2.1780us  2.1780us  cudaGetDevice\n",
            "                    0.00%  1.9590us         3     653ns     123ns  1.6400us  cuDeviceGetCount\n",
            "                    0.00%     792ns         2     396ns     129ns     663ns  cuDeviceGet\n",
            "                    0.00%     500ns         1     500ns     500ns     500ns  cuModuleGetLoadingMode\n",
            "                    0.00%     479ns         1     479ns     479ns     479ns  cuDeviceTotalMem\n",
            "                    0.00%     216ns         1     216ns     216ns     216ns  cuDeviceGetUuid\n",
            "\n",
            "==4109== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  11.12506ms  Host To Device\n",
            "      32  2.0000MB  2.0000MB  2.0000MB  64.00000MB  5.145451ms  Device To Host\n",
            "Total CPU Page faults: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA with Shared Memory"
      ],
      "metadata": {
        "id": "v37VyGxhnuuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hadamard_cuda_shared16x16.cu\n",
        "#include <cstddef>\n",
        "#include <cstdio>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "void dump_arr(size_t numCol, size_t numRow, float* Arr)\n",
        "{\n",
        "    for (size_t j = 0; j < numCol; ++j) {\n",
        "      for (size_t i = 0; i < numRow; ++i) {\n",
        "      printf(\"%.2f \", Arr[i * numCol + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void cuda_hadamard(size_t numCol, size_t numRow, float* Z, float* X, float* Y)\n",
        "{\n",
        "  size_t threadRowID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t threadColId = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  __shared__ float shData[1];\n",
        "\n",
        "  shData[0] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  Z[threadRowID * numCol + threadColId] = shData[0];\n",
        "\n",
        "  // Z[threadRowID * numCol + threadColId] = X[threadRowID * numCol + threadColId] * Y[threadRowID * numCol + threadColId];\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const size_t ARRAY_DIM = 4096;\n",
        "  const size_t ARRAY_BYTES = ARRAY_DIM * ARRAY_DIM * sizeof(float);\n",
        "  size_t NUM_EXEC = 30;\n",
        "\n",
        "  // Array Initialization\n",
        "  float* X;\n",
        "  float* Y;\n",
        "  float* Z;\n",
        "\n",
        "  // Initialize C implementation of Hadamard Product, reference for error checking\n",
        "  // float* C;\n",
        "  // C = (float*)malloc(ARRAY_DIM * ARRAY_DIM * sizeof(float));\n",
        "\n",
        "  // Array Malloc\n",
        "  cudaMallocManaged(&X, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&Z, ARRAY_BYTES);\n",
        "\n",
        "  // get gpu ID\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  // Mem advise\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(X, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(Y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  // \"prefetch data\" to create GPU page memory\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // initialize array contents\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j < ARRAY_DIM; ++j) {\n",
        "      X[ARRAY_DIM * i + j] = 1;\n",
        "      Y[ARRAY_DIM * i + j] = 1;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // \"Prefetch data\" from CPU-GPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // setup CUDA kernel\n",
        "  // https://www.cs.emory.edu/~cheung/Courses/355/Syllabus/94-CUDA/2D-grids.html\n",
        "  size_t threadDimBlockx = 32;\n",
        "  size_t threadDimBlocky = 32;\n",
        "\n",
        "  dim3 blockShape = dim3(threadDimBlockx, threadDimBlocky);\n",
        "  // https://selkie.macalester.edu/csinparallel/modules/GPUProgramming/build/html/CUDA2D/CUDA2D.html\n",
        "  // https://medium.com/@harsh20111997/cuda-programming-2d-convolution-8476300f566e\n",
        "  dim3 gridShape = dim3( (ARRAY_DIM + threadDimBlockx - 1) / threadDimBlockx, (ARRAY_DIM + threadDimBlocky - 1)/threadDimBlocky );\n",
        "\n",
        "  for (size_t i = 0; i < NUM_EXEC; ++i) {\n",
        "    cuda_hadamard <<< gridShape, blockShape >>> (ARRAY_DIM, ARRAY_DIM, Z, X, Y);\n",
        "  }\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // \"Prefetch data\" from GPU-CPU\n",
        "  cudaMemPrefetchAsync(X, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(Z, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "\n",
        "  // error checking\n",
        "  size_t errCount = 0;\n",
        "\n",
        "  for (size_t i = 0; i < ARRAY_DIM; ++i) {\n",
        "    for (size_t j = 0; j <ARRAY_DIM; ++j ) {\n",
        "      if (X[i * ARRAY_DIM + j] * Y[i * ARRAY_DIM + j] != Z[i * ARRAY_DIM + j]) {\n",
        "        errCount++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"Total error count: %lu\", errCount);\n",
        "\n",
        "  cudaFree(X);\n",
        "  cudaFree(Y);\n",
        "  cudaFree(Z);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHYiwnponuU4",
        "outputId": "ccbf0481-09a6-4791-cd6a-1c3e550fbb7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hadamard_cuda_shared16x16.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -o hadamard_cuda_shared16x16 hadamard_cuda_shared16x16.cu -arch=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_8LPlWMn312",
        "outputId": "8c4b9f3f-73bb-4757-9e8a-7efd6c12790c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./hadamard_cuda_shared16x16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5yu0MrvoIEQ",
        "outputId": "6d008b8c-40a8-4270-822b-81a04babeb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==3976== NVPROF is profiling process 3976, command: ./hadamard_cuda_shared16x16\n",
            "Total error count: 0==3976== Profiling application: ./hadamard_cuda_shared16x16\n",
            "==3976== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  131.78ms        30  4.3927ms  4.1460ms  4.5828ms  cuda_hadamard(unsigned long, unsigned long, float*, float*, float*)\n",
            "      API calls:   42.55%  131.70ms         1  131.70ms  131.70ms  131.70ms  cudaDeviceSynchronize\n",
            "                   38.29%  118.52ms         3  39.506ms  22.614us  118.43ms  cudaMallocManaged\n",
            "                   13.28%  41.096ms         8  5.1370ms  41.663us  14.596ms  cudaMemPrefetchAsync\n",
            "                    3.46%  10.717ms        30  357.24us  3.4900us  10.599ms  cudaLaunchKernel\n",
            "                    2.34%  7.2472ms         3  2.4157ms  2.2525ms  2.5137ms  cudaFree\n",
            "                    0.06%  171.40us       114  1.5030us     108ns  69.912us  cuDeviceGetAttribute\n",
            "                    0.01%  20.116us         4  5.0290us  1.1650us  15.455us  cudaMemAdvise\n",
            "                    0.00%  11.860us         1  11.860us  11.860us  11.860us  cuDeviceGetName\n",
            "                    0.00%  7.3960us         1  7.3960us  7.3960us  7.3960us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.9530us         3     651ns     151ns  1.5700us  cuDeviceGetCount\n",
            "                    0.00%  1.4930us         1  1.4930us  1.4930us  1.4930us  cudaGetDevice\n",
            "                    0.00%     810ns         2     405ns     121ns     689ns  cuDeviceGet\n",
            "                    0.00%     512ns         1     512ns     512ns     512ns  cuModuleGetLoadingMode\n",
            "                    0.00%     424ns         1     424ns     424ns     424ns  cuDeviceGetUuid\n",
            "                    0.00%     419ns         1     419ns     419ns     419ns  cuDeviceTotalMem\n",
            "\n",
            "==3976== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  11.12769ms  Host To Device\n",
            "      32  2.0000MB  2.0000MB  2.0000MB  64.00000MB  5.143854ms  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}